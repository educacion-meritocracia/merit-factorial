---
author: "Equipo EDUMER"
bibliography: "../input/bib/merit-factorial.bib"
csl: "../input/bib/apa6.csl"
editor_options: 
  chunk_output_type: console
---

## Invariance analysis

```{r}
#| echo: false
#| message: false
#| warning: false

library(knitr)

knitr::opts_chunk$set(echo = F,
                      warning = F,
                      error = F, 
                      message = F) 

table_format <- if (is_html_output()) {
  "html"
} else if (is_latex_output()) {
  "latex"
}
table_format2 <- if (is_html_output()) {
  T
} else if (is_latex_output()) {
  F
}

options(kableExtra.html.bsTable = T)
options(knitr.kable.NA = "")
```

```{r}
#| include: false
#| echo: false

if (!require("pacman")) install.packages("pacman")

pacman::p_load(
  tidyverse,
  sjmisc,
  sjPlot,
  here,
  lavaan,
  psych,
  corrplot,
  ggdist,
  patchwork,
  semTools,
  gtools,
  kableExtra
)

options(scipen = 999)
rm(list = ls())
```

```{r}
#| echo: false
#| output: false

load(file = here("output", "data", "db_long_proc.RData"))

names(db_long)
glimpse(db_long)
dim(db_long)
```

```{r}
#| label: data 2
#| results: asis
#| echo: false
#| warning: false
#| output: false

# Crear base en formato wide con dummy de cohorte (0 = primaria, 1 = secundaria)
db_invariance <- db_long %>%
  group_by(id_estudiante) %>%
  mutate(
    cohort_level = first(cohort_level),
    cohort_dummy = case_when(
      cohort_level == "Primary" ~ 0,
      cohort_level == "Secondary" ~ 1,
      TRUE ~ NA_real_
    )
  ) %>%
  ungroup() %>%
  select(id_estudiante, cohort_dummy, ola, starts_with(c("perc", "pref"))) %>%
  pivot_wider(
    id_cols = c(id_estudiante, cohort_dummy),
    names_from = ola,
    names_glue = "{.value}{ola}",
    values_from = c(
      perc_effort, perc_talent,
      perc_rich_parents, perc_contact,
      pref_effort, pref_talent,
      pref_rich_parents, pref_contact
    )
  ) %>%
  na.omit() %>%
  rename_with(~ str_replace_all(., "_", ""))

# Reescalar variables y convertir a ordinales
db_invariance <- db_invariance %>% 
  mutate(
    across(
      .cols = -c(idestudiante, cohortdummy),
      .fns = ~ case_when(. == 1 ~ 0,
                         . == 2 ~ 1,
                         . == 3 ~ 2,
                         . == 4 ~ 3)
    )
  ) %>%
  mutate(
    across(
      .cols = -c(idestudiante),
      .fns = ~ ordered(.)
    )
  )
```

```{r}
#| label: conf-model
#| tbl-cap: "Longitudinal Invariance Test"
#| results: asis
#| echo: false
#| warning: false

# First, define the configural model, using the repeated measures factors and
# indicators
baseline_model_smt <- ('

###########################################
# Definición de factores (1 marcador por factor)
###########################################

percmerit1  =~ 1*perceffort1     + perctalent1
percmerit2  =~ 1*perceffort2     + perctalent2

percnmerit1 =~ 1*percrichparents1 + perccontact1
percnmerit2 =~ 1*percrichparents2 + perccontact2

prefmerit1  =~ 1*prefeffort1     + preftalent1
prefmerit2  =~ 1*prefeffort2     + preftalent2

prefnmerit1 =~ 1*prefrichparents1 + prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + prefcontact2


###########################################
# Covarianzas entre errores (mismo ítem, distintas olas)
###########################################

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2

percrichparents1 ~~ percrichparents2
perccontact1     ~~ perccontact2

prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2

prefrichparents1 ~~ prefrichparents2
prefcontact1     ~~ prefcontact2
')



# Model Estimation
fit_baseline <- cfa(baseline_model_smt, data = db_invariance,
                    ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                    parameterization = "theta",
                    estimator = "WLSMV")
```

```{r}
#| label: Weak-Model
#| tbl-cap: "Longitudinal Invariance Weak Model"
#| results: asis
#| echo: false
#| warning: false

loadinginv_model_smt <- ('

# Igualación de cargas (invarianza débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Umbrales (uno igualado por ítem)

# perceffort1 | pe1t1*t1 + pe1t2*t2
# perceffort2 | pe2t1*t1 + pe2t2*t2
# perctalent1 | pt1t1*t1 + pt1t2*t2
# perctalent2 | pt2t1*t1 + pt2t2*t2
# percrichparents1 | prp1t1*t1 + prp1t2*t2
# percrichparents2 | prp2t1*t1 + prp2t2*t2
# perccontact1 | pc1t1*t1 + pc1t2*t2
# perccontact2 | pc2t1*t1 + pc2t2*t2
# prefeffort1 | pre1t1*t1 + pre1t2*t2
# prefeffort2 | pre2t1*t1 + pre2t2*t2
# preftalent1 | prt1t1*t1 + prt1t2*t2
# preftalent2 | prt2t1*t1 + prt2t2*t2
# prefrichparents1 | pfrp1t1*t1 + pfrp1t2*t2
# prefrichparents2 | pfrp2t1*t1 + pfrp2t2*t2
# prefcontact1 | pfc1t1*t1 + pfc1t2*t2
# prefcontact2 | pfc2t1*t1 + pfc2t2*t2
 

# Covarianzas entre errores

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2
')


fit_loadinginv <- cfa(loadinginv_model_smt, data = db_invariance,
                      ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                  "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                  "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                  "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                      parameterization = "theta",
                      estimator = "WLSMV")
```

```{r}
#| label: strong-model
#| tbl-cap: "Longitudinal Invariance Strong Model"
#| results: asis
#| echo: false
#| warning: false

thresholdinv_model_smt <- ('

# Igualación de cargas (como en el modelo débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Thresholds iguales entre olas (invarianza fuerte)

perceffort1     | pe_t1*t1 + pe_t2*t2
perceffort2     | pe_t1*t1 + pe_t2*t2
perctalent1     | pt_t1*t1 + pt_t2*t2
perctalent2     | pt_t1*t1 + pt_t2*t2
percrichparents1| prp_t1*t1 + prp_t2*t2
percrichparents2| prp_t1*t1 + prp_t2*t2
perccontact1    | pc_t1*t1 + pc_t2*t2
perccontact2    | pc_t1*t1 + pc_t2*t2
prefeffort1     | pre_t1*t1 + pre_t2*t2
prefeffort2     | pre_t1*t1 + pre_t2*t2
preftalent1     | prt_t1*t1 + prt_t2*t2
preftalent2     | prt_t1*t1 + prt_t2*t2
prefrichparents1| pfrp_t1*t1 + pfrp_t2*t2
prefrichparents2| pfrp_t1*t1 + pfrp_t2*t2
prefcontact1    | pfc_t1*t1 + pfc_t2*t2
prefcontact2    | pfc_t1*t1 + pfc_t2*t2


# Interceptos fijos

perceffort1 + perctalent1 ~ 0*1
perceffort2 + perctalent2 ~ 0*1
percrichparents1 + perccontact1 ~ 0*1
percrichparents2 + perccontact2 ~ 0*1
prefeffort1 + preftalent1 ~ 0*1
prefeffort2 + preftalent2 ~ 0*1
prefrichparents1 + prefcontact1 ~ 0*1
prefrichparents2 + prefcontact2 ~ 0*1


# Varianzas únicas

perceffort1 ~~ 1*perceffort1
perctalent1 ~~ 1*perctalent1
percrichparents1 ~~ 1*percrichparents1
perccontact1 ~~ 1*perccontact1
prefeffort1 ~~ 1*prefeffort1
preftalent1 ~~ 1*preftalent1
prefrichparents1 ~~ 1*prefrichparents1
prefcontact1 ~~ 1*prefcontact1

perceffort2 ~~ NA*perceffort2
perctalent2 ~~ NA*perctalent2
percrichparents2 ~~ NA*percrichparents2
perccontact2 ~~ NA*perccontact2
prefeffort2 ~~ NA*prefeffort2
preftalent2 ~~ NA*preftalent2
prefrichparents2 ~~ NA*prefrichparents2
prefcontact2 ~~ NA*prefcontact2


# Covarianzas entre errores longitudinales

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2
')

fit_thresholdinv <- cfa(thresholdinv_model_smt, data = db_invariance,
                        ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                    "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                    "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                    "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                        parameterization = "theta",
                        estimator = "WLSMV")
```

```{r}
#| label: strict-model
#| tbl-cap: "Longitudinal Invariance Strict Model"
#| results: asis
#| echo: false
#| warning: false

uniquenessinv_model_smt <- ('

# Cargas factoriales (invarianza débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas de factores latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Medias latentes

percmerit1  ~ 0*1
percmerit2  ~ 1
percnmerit1 ~ 0*1
percnmerit2 ~ 1
prefmerit1  ~ 0*1
prefmerit2  ~ 1
prefnmerit1 ~ 0*1
prefnmerit2 ~ 1


# Umbrales (invarianza fuerte)

perceffort1     | pe_t1*t1 + pe_t2*t2
perceffort2     | pe_t1*t1 + pe_t2*t2
perctalent1     | pt_t1*t1 + pt_t2*t2
perctalent2     | pt_t1*t1 + pt_t2*t2
percrichparents1| prp_t1*t1 + prp_t2*t2
percrichparents2| prp_t1*t1 + prp_t2*t2
perccontact1    | pc_t1*t1 + pc_t2*t2
perccontact2    | pc_t1*t1 + pc_t2*t2
prefeffort1     | pre_t1*t1 + pre_t2*t2
prefeffort2     | pre_t1*t1 + pre_t2*t2
preftalent1     | prt_t1*t1 + prt_t2*t2
preftalent2     | prt_t1*t1 + prt_t2*t2
prefrichparents1| pfrp_t1*t1 + pfrp_t2*t2
prefrichparents2| pfrp_t1*t1 + pfrp_t2*t2
prefcontact1    | pfc_t1*t1 + pfc_t2*t2
prefcontact2    | pfc_t1*t1 + pfc_t2*t2


# Interceptos fijos

perceffort1 + perctalent1 ~ 0*1
perceffort2 + perctalent2 ~ 0*1
percrichparents1 + perccontact1 ~ 0*1
percrichparents2 + perccontact2 ~ 0*1
prefeffort1 + preftalent1 ~ 0*1
prefeffort2 + preftalent2 ~ 0*1
prefrichparents1 + prefcontact1 ~ 0*1
prefrichparents2 + prefcontact2 ~ 0*1


# Varianzas únicas (invarianza estricta)
# Fijadas a 1 en todas las olas

perceffort1 ~~ 1*perceffort1
perceffort2 ~~ 1*perceffort2
perctalent1 ~~ 1*perctalent1
perctalent2 ~~ 1*perctalent2

percrichparents1 ~~ 1*percrichparents1
percrichparents2 ~~ 1*percrichparents2
perccontact1 ~~ 1*perccontact1
perccontact2 ~~ 1*perccontact2

prefeffort1 ~~ 1*prefeffort1
prefeffort2 ~~ 1*prefeffort2
preftalent1 ~~ 1*preftalent1
preftalent2 ~~ 1*preftalent2

prefrichparents1 ~~ 1*prefrichparents1
prefrichparents2 ~~ 1*prefrichparents2
prefcontact1 ~~ 1*prefcontact1
prefcontact2 ~~ 1*prefcontact2


# Covarianzas entre errores (mismo ítem, diferente ola)

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2
')

fit_uniquenessinv <- cfa(uniquenessinv_model_smt, data = db_invariance,
                         ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                     "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                     "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                     "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                         parameterization = "theta",
                         estimator = "WLSMV")
```


We assessed measurement invariance through a hierarchical sequence of nested confirmatory factor analysis models in which progressively stronger equality constraints were imposed to evaluate whether the measurement model was comparable across time and cohorts. For longitudinal invariance, we followed the approach in @liu_testing_2017 and estimated the model simultaneously across the two waves, starting with a configural model that specified the same factor structure at each wave while allowing item parameters (factor loadings, thresholds/intercepts, and residual variances) to vary freely; this model served as the baseline for subsequent comparisons. We then tested metric (weak) invariance by constraining factor loadings to equality across waves, followed by scalar (strong) invariance by additionally constraining item thresholds (and, where applicable, intercepts) to equality over time—an essential step with ordered-categorical indicators to ensure that response categories map onto equivalent points on the latent continuum and thus permit meaningful comparisons of latent means. Finally, we evaluated strict invariance by further constraining residual variances to equality across waves. To assess invariance between cohorts, we followed the sequential procedure proposed by @svetina_multiplegroup_2020a for ordinal indicators: we estimated a configural model, then a threshold-invariant model, and finally a model that jointly constrained thresholds and factor loadings across groups.

In the following sections, we proceed as follows. First, we report descriptive statistics for the meritocracy scale across waves. Second, we present the results of the measurement invariance analyses, emphasizing the highest level of invariance achieved in each comparison. Finally, we examine potential sources of non-invariance to identify which items or parameters drive any lack of equivalence.


### Longitudinal invariance

@fig-likerplot1 display the response distributions for the meritocracy scale, distinguishing perceptions (Panel A) from preferences (Panel B) across waves. In Wave 1 perceptions, agreement is highly concentrated across items, especially for contacts (77.2%), talent (73.4%), and having rich parents (71.4%), with effort also widely endorsed (66.9); at the same time, sizeable minorities disagree (33.1% for effort, 28.6% for rich parents, and 26.6% for talent), indicating a dual recognition in which students strongly acknowledge non-meritocratic determinants (contacts and parental wealth) while, within meritocratic dimensions, viewing talent as more influential than effort—the least perceived as rewarded. Wave 1 preferences show the inverse pattern: effort is overwhelmingly endorsed as the legitimate basis for rewards (87.9%), far exceeding its perceived role in practice; views on talent are split (54% agree, 45% disagree); parental wealth remains nearly evenly divided; and contacts are relatively more accepted than rejected (60.9% vs. 39.1%), suggesting that this factor is not uniformly considered illegitimate in the “ideal” society.

Wave 2 largely replicates these patterns with modest shifts. In perceptions, endorsement of effort declines (61.5%), whereas contacts (76.6%), talent (69.9%), and parental wealth (69.8%) remain consistently high. In preferences, support for effort remains extremely stable (88.2%), while support for talent declines, with disagreement rising to 50.5%. Attitudes toward parental wealth remain evenly divided, and contacts continue to be more accepted than rejected (59.1% vs. 39.1%), albeit far below the near-consensus around effort. Overall, both waves reveal a stable gap: students perceive social outcomes as strongly shaped by non-meritocratic factors (especially contacts and family wealth) and, to a lesser extent, talent, yet they overwhelmingly endorse an effort-centered meritocratic ideal. This persistent divergence between perceived reality and normative preferences highlights a key paradox—strong support for meritocracy as a principle alongside skepticism about its realization in practice.


```{r}
#| label: fig-likerplot1
#| fig-align: center
#| fig-cap: "Distribution of responses on the scale of perceptions and preferences regarding meritocracy by wave"
#| fig-cap-location: top
#| fig-asp: 0.8
#| out-width: '80%'
#| echo: false
#| warning: false
#| message: false

# paquetes
library(dplyr)
library(ggplot2)
library(cowplot)
library(tibble)

# 1) preparar bases (olas 1 y 2)
db_likert1 <- db_long %>%
  filter(ola == 1) %>%
  select(starts_with(c("perc", "pref"))) %>%
  na.omit() %>%
  mutate(
    across(
      .cols = c(starts_with(c("perc", "pref"))),
      .fns  = ~ sjlabelled::set_labels(
        .,
        labels = c(
          "Strongly disagree" = 1,
          "Disagree"          = 2,
          "Agree"             = 3,
          "Strongly agree"    = 4
        )
      )
    )
  )

db_likert2 <- db_long %>%
  filter(ola == 2) %>%
  select(starts_with(c("perc", "pref"))) %>%
  na.omit() %>%
  mutate(
    across(
      .cols = c(starts_with(c("perc", "pref"))),
      .fns  = ~ sjlabelled::set_labels(
        .,
        labels = c(
          "Strongly disagree" = 1,
          "Disagree"          = 2,
          "Agree"             = 3,
          "Strongly agree"    = 4
        )
      )
    )
  )

# 2) settings
theme_set(theme_ggdist())
colors <- RColorBrewer::brewer.pal(n = 4, name = "RdBu")

# 3) los 4 likert plots (sin leyenda, porque la haremos a mano abajo)
a <- db_likert1 %>%
  select(starts_with("perc")) %>%
  sjPlot::plot_likert(
    geom.colors    = colors,
    title          = "Perceptions",
    axis.labels    = c("Effort", "Talent", "Rich parents", "Contacts"),
    catcount       = 4,
    values         = "sum.outside",
    reverse.colors = FALSE,
    reverse.scale  = TRUE,
    show.n         = FALSE,
    show.prc.sign  = TRUE
  ) +
  theme(legend.position = "none")

b <- db_likert1 %>%
  select(starts_with("pref")) %>%
  sjPlot::plot_likert(
    geom.colors    = colors,
    title          = "Preferences",
    axis.labels    = c("Effort", "Talent", "Rich parents", "Contacts"),
    catcount       = 4,
    values         = "sum.outside",
    reverse.colors = FALSE,
    reverse.scale  = TRUE,
    show.n         = FALSE,
    show.prc.sign  = TRUE
  ) +
  theme(legend.position = "none")

c <- db_likert2 %>%
  select(starts_with("perc")) %>%
  sjPlot::plot_likert(
    geom.colors    = colors,
    title          = "Perceptions",
    axis.labels    = c("Effort", "Talent", "Rich parents", "Contacts"),
    catcount       = 4,
    values         = "sum.outside",
    reverse.colors = FALSE,
    reverse.scale  = TRUE,
    show.n         = FALSE,
    show.prc.sign  = TRUE
  ) +
  theme(legend.position = "none")

d <- db_likert2 %>%
  select(starts_with("pref")) %>%
  sjPlot::plot_likert(
    geom.colors    = colors,
    title          = "Preferences",
    axis.labels    = c("Effort", "Talent", "Rich parents", "Contacts"),
    catcount       = 4,
    values         = "sum.outside",
    reverse.colors = FALSE,
    reverse.scale  = TRUE,
    show.n         = FALSE,
    show.prc.sign  = TRUE
  ) +
  theme(legend.position = "none")

# 4) grilla 2x2
panels <- plot_grid(a, b, c, d, ncol = 2, align = "hv", axis = "tblr")

# 5) poner Wave 1 / Wave 2 encima (no consume ancho)
panels_labeled <- ggdraw(panels) +
  draw_label("Wave 1", x = 0.03, y = 0.75, angle = 0, hjust = 1.5, vjust = 0.5, size = 11) +
  draw_label("Wave 2", x = 0.03, y = 0.25, angle = 0, hjust = 1.5, vjust = 0.5, size = 11)

# 6) leyenda a mano COMO PANEL (sin extraer grobs)
lik_labels <- c("Strongly disagree", "Disagree", "Agree", "Strongly agree")
df_leg <- tibble(cat = factor(lik_labels, levels = lik_labels))

legend_only <- ggplot(df_leg, aes(x = 2, y = 2, fill = cat)) +
  geom_point(shape = 22, size = 6, color = "black", stroke = 0.3) +
  coord_cartesian(xlim = c(0, 1), ylim = c(0, 1), clip = "on") +  # “esconde” los puntos
  scale_fill_manual(values = colors, drop = FALSE) +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE, title = NULL)) +
  theme_void() +
  theme(
    legend.position = "bottom",
    legend.text     = element_text(size = 9),
    legend.key.size = unit(4, "mm"),
    plot.margin     = margin(0, 0, 0, 0)
  )
# 7) caption común como panel
cap <- ggdraw() +
  draw_label("Source: own elaboration based on EDUMER Panel Survey (N Wave 1 =  846; N Wave 2 = 662) ", x = 0, hjust = -1.2, size = 9)

# 8) final: todo junto
final <- plot_grid(
  panels_labeled,
  legend_only,
  cap,
  ncol = 1,
  rel_heights = c(2, 0.10, 0.06)
)

final +
  theme(plot.margin = margin(t = 5.5, r = 5.5, b = 5.5, l = 40))

```



@tbl-longinv reports the results of the longitudinal invariance tests. Overall, the scale achieved the strongest level of invariance (strict invariance) across the two waves. The strict model showed good fit, $\chi^2$(84) = 130.17, CFI = 0.991, RMSEA = 0.031 (90% CI: 0.020–0.040). Moreover, compared with the strong (scalar) model, the deterioration in fit was negligible: $\Delta \chi^2$(4) = 1.635, $\Delta$CFI = 0.000, and $\Delta$RMSEA = -0.002. These differences fall well within commonly used cutoffs for invariance evaluation, indicating that constraining residual variances in addition to loadings and thresholds/intercepts is tenable. Substantively, this implies that the item–factor relations are stable over time (metric invariance) and that, for a given level of the latent trait, respondents are expected to endorse the same response categories across waves (scalar invariance), supporting the comparability of scores and latent parameters within students over time.

```{r}
#| tbl-cap: "Longitudinal invariance results"
#| tbl-cap-location: top
#| echo: false
#| warning: false
#| label: tbl-longinv

# Compare fit

an1 <- anova(fit_baseline, fit_loadinginv)
an2 <- anova(fit_loadinginv, fit_thresholdinv)
an3 <- anova(fit_thresholdinv, fit_uniquenessinv)

tab01 <- bind_rows(
  as_tibble(an1)[2,],
  as_tibble(an2)[2,],
  as_tibble(an3)[2,]
) %>%
  select("Chisq", "Df", chisq_diff = `Chisq diff`, df_diff = `Df diff`, pvalue = `Pr(>Chisq)`) %>%
  mutate(
    stars = stars.pval(pvalue),
    chisqt = paste0(round(Chisq, 2), " (", Df, ")"),
    decision = ifelse(pvalue > 0.05, "Accept", "Reject"),
    model = c("Weak", "Strong", "Strict")
  ) %>%
  bind_rows(
    tibble(Chisq = an1$Chisq[1], Df = an1$Df[1], chisq_diff = NA, df_diff = NA,
           pvalue = NA, stars = "", chisqt = paste0(round(an1$Chisq[1], 2), " (", an1$Df[1], ")"),
           decision = "Reference", model = "Configural")
  ) %>%
  select(model, chisqt, chisq_diff, df_diff, pvalue, stars, decision) %>%
  mutate(model = factor(model, levels = c("Configural", "Weak", "Strong", "Strict"))) %>%
  arrange(model)


fit.meas <- dplyr::bind_rows(lavaan::fitmeasures(fit_baseline, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_loadinginv,  output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_thresholdinv, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_uniquenessinv, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),])

fit.meas <- fit.meas %>%
  dplyr::mutate(diff.chi2 = chisq    - lag(chisq,default = dplyr::first(chisq)),
                diff.df   = df       - lag(df,   default = dplyr::first(df)),
                diff.cfi  = cfi      - lag(cfi,  default = dplyr::first(cfi)),
                diff.rmsea   = rmsea - lag(rmsea,default = dplyr::first(rmsea))) %>%
  round(3) %>%
  dplyr::mutate(rmsea.ci=paste0(rmsea," \n ", "(",rmsea.ci.lower,"-",rmsea.ci.upper,")"))

tab.inv <- dplyr::bind_cols(tab01,fit.meas) %>%
  dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.df,diff.cfi,diff.rmsea,stars,decision) %>%
  dplyr::mutate(diff.chi2=paste0(diff.chi2," (",diff.df,") ",stars)) %>%
  dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.cfi,diff.rmsea,decision)


col.nam <- c("Model","&chi;^2 (df)","CFI","RMSEA (90 CI)",
             "&Delta; &chi;^2 (&Delta; df)","&Delta; CFI","&Delta; RMSEA","Decision")

tab.inv %>% 
  kableExtra::kable(format = "html",
                    align = "c",
                    booktabs = T,
                    escape = F,
                    caption = NULL,
                    col.names = col.nam) %>%
  kableExtra::kable_styling(full_width = T,
                            latex_options = "hold_position",
                            bootstrap_options=c("striped", "bordered", "condensed"),
                            font_size = 23) %>%
  kableExtra::column_spec(c(1,8), width = "3.5cm") %>% 
  kableExtra::column_spec(2:7, width = "4cm") %>% 
  kableExtra::column_spec(4, width = "5cm")
```


Taken together, the results support full longitudinal measurement invariance—configural, metric, scalar, and strict—suggesting that the constructs are measured equivalently across waves. This provides a strong basis for comparing latent means as well as variances/covariances and structural relations over time. As an additional diagnostic, we examined potential sources of localized misfit using univariate score tests at each step of the invariance hierarchy (configural, metric, scalar, and strict) via `lavTestScore` in lavaan. The score tests did not reveal statistically meaningful violations of the imposed equality constraints: loadings were supported at the metric level; loadings and thresholds remained stable in the scalar model; and residual variances also appeared invariant under the strict model. The most significant modification signal concerned one threshold of the preference-for-talent indicator ($\chi^2$ = 3.829, p = .050), which did not reach conventional significance. Full score-test outputs are reported in the supplementary materials.


### Cohort invariance

@fig-likerplot2 shows response distributions by cohort, separating perceptions and preferences. In primary education, perceived rewards are similar for effort and talent (both 76% agree). Contacts (66.8%) and a rich-family background (59%) are also seen as rewarded, and these non-meritocratic factors elicit the most disagreement within the cohort (41% disagree with rich-family background; 33.2% with contacts). In preferences, effort is clearly dominant (84.1% agree), whereas talent and a rich family background split evenly (50% agree/50% disagree). Notably, 62% view it as good that those who have good contacts do better in life (38% disagree).



```{r}
#| label: fig-likerplot2
#| fig-align: center
#| fig-cap: "Distribution of responses on the scale of perceptions and preferences regarding meritocracy by cohort"
#| fig-cap-location: top
#| fig-width: 7
#| out-width: '80%'
#| echo: false
#| warning: false
#| message: false

# 1) preparar bases (olas 1 y 2)
db_likert1 <- db_long %>%
  filter(cohort_level == "Primary") %>%
  select(starts_with(c("perc", "pref"))) %>%
  na.omit() %>%
  mutate(
    across(
      .cols = c(starts_with(c("perc", "pref"))),
      .fns  = ~ sjlabelled::set_labels(
        .,
        labels = c(
          "Strongly disagree" = 1,
          "Disagree"          = 2,
          "Agree"             = 3,
          "Strongly agree"    = 4
        )
      )
    )
  )

db_likert2 <- db_long %>%
  filter(cohort_level == "Secondary") %>%
  select(starts_with(c("perc", "pref"))) %>%
  na.omit() %>%
  mutate(
    across(
      .cols = c(starts_with(c("perc", "pref"))),
      .fns  = ~ sjlabelled::set_labels(
        .,
        labels = c(
          "Strongly disagree" = 1,
          "Disagree"          = 2,
          "Agree"             = 3,
          "Strongly agree"    = 4
        )
      )
    )
  )

# 3) los 4 likert plots (sin leyenda, porque la haremos a mano abajo)
a <- db_likert1 %>%
  select(starts_with("perc")) %>%
  sjPlot::plot_likert(
    geom.colors    = colors,
    title          = "Perceptions",
    axis.labels    = c("Effort", "Talent", "Rich parents", "Contacts"),
    catcount       = 4,
    values         = "sum.outside",
    reverse.colors = FALSE,
    reverse.scale  = TRUE,
    show.n         = FALSE,
    show.prc.sign  = TRUE
  ) +
  theme(legend.position = "none")

b <- db_likert1 %>%
  select(starts_with("pref")) %>%
  sjPlot::plot_likert(
    geom.colors    = colors,
    title          = "Preferences",
    axis.labels    = c("Effort", "Talent", "Rich parents", "Contacts"),
    catcount       = 4,
    values         = "sum.outside",
    reverse.colors = FALSE,
    reverse.scale  = TRUE,
    show.n         = FALSE,
    show.prc.sign  = TRUE
  ) +
  theme(legend.position = "none")

c <- db_likert2 %>%
  select(starts_with("perc")) %>%
  sjPlot::plot_likert(
    geom.colors    = colors,
    title          = "Perceptions",
    axis.labels    = c("Effort", "Talent", "Rich parents", "Contacts"),
    catcount       = 4,
    values         = "sum.outside",
    reverse.colors = FALSE,
    reverse.scale  = TRUE,
    show.n         = FALSE,
    show.prc.sign  = TRUE
  ) +
  theme(legend.position = "none")

d <- db_likert2 %>%
  select(starts_with("pref")) %>%
  sjPlot::plot_likert(
    geom.colors    = colors,
    title          = "Preferences",
    axis.labels    = c("Effort", "Talent", "Rich parents", "Contacts"),
    catcount       = 4,
    values         = "sum.outside",
    reverse.colors = FALSE,
    reverse.scale  = TRUE,
    show.n         = FALSE,
    show.prc.sign  = TRUE
  ) +
  theme(legend.position = "none")

# 4) grilla 2x2
panels <- plot_grid(a, b, c, d, ncol = 2, align = "hv", axis = "tblr")

# 5) poner Wave 1 / Wave 2 encima (no consume ancho)
panels_labeled <- ggdraw(panels) +
  draw_label("Primary", x = 0.03, y = 0.75, angle = 0, hjust = 1.5, vjust = 0.5, size = 11) +
  draw_label("Secondary", x = 0.03, y = 0.25, angle = 0, hjust = 1.5, vjust = 0.5, size = 11)

# 6) leyenda a mano COMO PANEL (sin extraer grobs)
lik_labels <- c("Strongly disagree", "Disagree", "Agree", "Strongly agree")
df_leg <- tibble(cat = factor(lik_labels, levels = lik_labels))

legend_only <- ggplot(df_leg, aes(x = 2, y = 2, fill = cat)) +
  geom_point(shape = 22, size = 6, color = "black", stroke = 0.3) +
  coord_cartesian(xlim = c(0, 1), ylim = c(0, 1), clip = "on") +  # “esconde” los puntos
  scale_fill_manual(values = colors, drop = FALSE) +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE, title = NULL)) +
  theme_void() +
  theme(
    legend.position = "bottom",
    legend.text     = element_text(size = 9),
    legend.key.size = unit(4, "mm"),
    plot.margin     = margin(0, 0, 0, 0)
  )
# 7) caption común como panel
cap <- ggdraw() +
  draw_label("Source: own elaboration based on EDUMER Panel Survey (N Primary =  725; N Secondary = 783) ", x = 0, hjust = -1.2, size = 9)

# 8) final: todo junto
final <- plot_grid(
  panels_labeled,
  legend_only,
  cap,
  ncol = 1,
  rel_heights = c(2, 0.10, 0.06)
)

final +
  theme(plot.margin = margin(t = 5.5, r = 5.5, b = 5.5, l = 60))

```

In secondary education, perceptions shift: disagreement that effort is rewarded increases (45.6%), and agreement decreases (54%). Disagreement about talent also increases (31.5%). The largest differences concern non-meritocratic factors, which are overwhelmingly perceived as rewarded (82% for rich-family background; 86% for contacts), with a stronger concentration in the highest agreement category. Preferences again strongly favor effort, while views on talent, rich-family background, and contacts remain mixed (roughly 45% disagree to 58% agree across items).


```{r}
#| echo: false
#| include: false


db1 <- db_long %>%
filter(ola == 1) %>% # quedarse con solo la ola 1
select(id_estudiante, starts_with(c("perc", "pref")), cohort_level)

model_restricted <- ('
perc_merit =~ perc_effort + perc_talent
perc_nmerit =~ a*perc_rich_parents + a*perc_contact
pref_merit =~ pref_effort + pref_talent
pref_nmerit =~ pref_rich_parents + pref_contact
perc_effort ~~ pref_talent
')


mbasica_cfa <- cfa(model = model_restricted, 
                   data = subset(db1, cohort_level == "Primary"), 
                   estimator = "WLSMV",
                   ordered = T,
                   std.lv = F)

mmedia_cfa <- cfa(model = model_restricted, 
                  data = subset(db1, cohort_level == "Secondary"), 
                  estimator = "WLSMV",
                  ordered = T,
                  std.lv = F)

summary(mmedia_cfa, standardized = TRUE, fit.measures = TRUE)
summary(mbasica_cfa, standardized = TRUE, fit.measures = TRUE)

modificationIndices(mmedia_cfa) %>% 
  filter(mi > 3.84)
```

```{r}
#| label: configural model
#| include: false 

baseline <- measEq.syntax(
  configural.model = model_restricted, # se especifica el modelo que se usará
  data = db1,
  ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact", # se explicita que las 
              "pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"),# variables son ordinales 
  parameterization = "theta", #parametrización ideal para indicadores ordinales
  ID.fac = "std.lv", # identidica el factor con varianza 1
  ID.cat = "Wu.Estabrook.2016", # tipo de estrategia ideal para indicadores ordinales
  group = "cohort_level", # identificación de los grupos
  group.equal = "configural" # nivel de invarianza 
)

model.baseline <- as.character(baseline) # se crea un objeto con el modelo configural como caracter para que puedan visualizarse sus datos

fit.baseline <- cfa(model.baseline, data = db1, group = "cohort_level",
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact", 
              "pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"))

summary(fit.baseline, fit.measures = T, standardized = T)
modificationIndices(fit.baseline) %>% 
  filter(mi > 3.84)
```

```{r}
#| label: weak model
#| include: false

# los siguientes dos modelos siguen los pasos de análisis de Dubravka et al, 2019.

thresholds <- measEq.syntax(
configural.model = model_restricted,
data = db1,
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact",
"pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"),
parameterization = "theta",
ID.fac = "std.lv",
ID.cat = "Wu.Estabrook.2016",
group = "cohort_level",
group.equal = c("thresholds") # aquí se aplica lo mismo que el código anterior excepto que ahora se restringen los thresholds
)

model.thres <- as.character(thresholds)

fit.thres <- cfa(model.thres, data = db1, group = "cohort_level",
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact",
"pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"))

summary(fit.thres, fit.measures = TRUE)
lavTestScore(fit.thres)
pt <- lavaan::parTable(fit.thres)

pt[pt$plabel %in% c(".p9.", ".p10.", ".p80.", ".p81."),
   c("id","group","lhs","op","rhs","label","plabel","free","ustart","est")]
```

```{r}
#| label: loading-threshold model
#| include: false

strong <- measEq.syntax(
configural.model = model_restricted,
data = db1,
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact",
"pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"),
parameterization = "theta",
ID.fac = "std.lv",
ID.cat = "Wu.Estabrook.2016",
group = "cohort_level",
group.equal = c("thresholds", "loadings") # ahora se restringen los tresholds y las cargas factoriales
)

model.strong <- as.character(strong)

fit.strong <- cfa(model.strong, data = db1, group = "cohort_level",
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact",
"pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"))

summary(fit.strong, fit.measures = TRUE)

```

```{r}
#| echo: false
#| label: tbl-cohort2
#| tbl-cap: Cohort (multigroup) invariance results
#| tbl-cap-location: top

# Comparaciones de Chi²
an1 <- anova(fit.baseline, fit.thres)
an2 <- anova(fit.thres, fit.strong)

tab01 <- bind_rows(
  as_tibble(an1)[2,],
  as_tibble(an2)[2,] # aqui se toma la segunda fila de comparación de cada anova
) %>%
  select("Chisq", "Df", chisq.diff = `Chisq diff`, df.diff = `Df diff`, pvalue = `Pr(>Chisq)`) %>%
  mutate(
    stars = stars.pval(pvalue),
    chisqt = paste0(round(Chisq, 2), " (", Df, ")"),
    decision = ifelse(pvalue > 0.05, "Accept", "Reject"),
    model = c("Tresholds", "Tresholds + Loadings") # etiqueta los modelos que se extraen de los anova
  ) %>%
  bind_rows(
    tibble(
      Chisq = an1$Chisq[1],
      Df = an1$Df[1],
      chisq.diff = NA,
      df.diff = NA,
      pvalue = NA,
      stars = "",
      chisqt = paste0(round(an1$Chisq[1], 2), " (", an1$Df[1], ")"),
      decision = "Reference",
      model = "Configural" # se añade el modelo configural como referencia para clarificar la comparación
    )
  ) %>%
  select(model, chisqt, chisq.diff, df.diff, pvalue, stars, decision) %>%
  mutate(model = factor(model, levels = c("Configural", "Tresholds", "Tresholds + Loadings"))) %>%
  arrange(model)

# se extraen los índices de ajuste para cada modelo
fit.meas <- bind_rows(
  fitMeasures(fit.baseline, output = "matrix")[c("chisq", "df", "cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"),],
  fitMeasures(fit.thres, output = "matrix")[c("chisq", "df", "cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"),],
  fitMeasures(fit.strong, output = "matrix")[c("chisq", "df", "cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"),]
)

fit.meas <- fit.meas %>% # se calculan las diferencias de cada modelo con el anterior para 
  mutate(                # analizar si se cumplen criterios de invarianza 
    diff.chi2 = chisq - lag(chisq, default = first(chisq)),
    diff.df = df - lag(df, default = first(df)),
    diff.cfi = cfi - lag(cfi, default = first(cfi)),
    diff.rmsea = rmsea - lag(rmsea, default = first(rmsea))
  ) %>%
  round(3) %>%
  mutate(rmsea.ci = paste0(rmsea, " \n(", rmsea.ci.lower, "-", rmsea.ci.upper, ")"))

# Tabla final (mantener diff.df hasta formatear)
tab.inv <- bind_cols(tab01, fit.meas) %>%
  select(model, chisqt, cfi, rmsea.ci, diff.chi2, diff.df, diff.cfi, diff.rmsea, stars, decision) %>%
  mutate(diff.chi2 = paste0(diff.chi2, " (", diff.df, ") ", stars)) %>%
  select(model, chisqt, cfi, rmsea.ci, diff.chi2, diff.cfi, diff.rmsea, decision)

# Encabezados de columna
col.nam <- c(
  "Model", "&chi;^2 (df)", "CFI", "RMSEA (90 CI)",
  "&Delta; &chi;^2 (&Delta; df)", "&Delta; CFI", "&Delta; RMSEA", "Decision"
)

# Se formatea la tabla en kable
tab.inv %>%
  kableExtra::kable(
    format = "html",
    align = "c",
    booktabs = TRUE,
    escape = FALSE,
    col.names = col.nam
  ) %>%
  kableExtra::kable_styling(
    full_width = TRUE,
    latex_options = "hold_position",
    bootstrap_options = c("striped", "bordered", "condensed"),
    font_size = 23
  ) %>%
  kableExtra::column_spec(c(1, 8), width = "3.5cm") %>%
  kableExtra::column_spec(2:7, width = "4cm") %>%
  kableExtra::column_spec(4, width = "5cm")

```

@tbl-cohort2 summarizes the cohort invariance tests. Overall, the results indicate that the scale achieves only configural invariance between primary and secondary students (i.e., the same four-factor structure), but fails to reach threshold and thus also fails to reach metric/scalar invariance. When equality constraints on thresholds were imposed, model fit ($\Delta$CFI = −.003; $\Delta$RMSEA = .006) deteriorated beyond commonly used criteria [@chen_sensitivity_2007], implying systematic differences in how response categories map onto the latent constructs across cohorts. In substantive terms, this means that primary and secondary students do not use the response scale equivalently when evaluating the acceptability of meritocratic and non-meritocratic criteria, which limits direct comparisons of latent scores across educational levels.

To identify the source of non-invariance, we inspected univariate score tests using `lavTestScore`. The largest misfit was concentrated in the thresholds of the effort-perception item, indicating that cohort differences are driven less by the factor structure than by differential category functioning in this specific indicator. Substantively, primary and secondary students appear to use the response options differently when assessing whether effort is rewarded in society, consistent with developmental and socialization processes through which older students may adopt a more critical view of the extent to which effort translates into success.

### Conditional longitudinal invariance by cohort



```{r}
#| echo: false
#| warning: false

# Modelo CFA configural con cohorte como covariable (control)
model_configural_cohort <- ('
percmerit1  =~ 1*perceffort1     + perctalent1
percmerit2  =~ 1*perceffort2     + perctalent2
percnmerit1 =~ 1*percrichparents1 + perccontact1
percnmerit2 =~ 1*percrichparents2 + perccontact2
prefmerit1  =~ 1*prefeffort1     + preftalent1
prefmerit2  =~ 1*prefeffort2     + preftalent2
prefnmerit1 =~ 1*prefrichparents1 + prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + prefcontact2

# Covarianzas entre errores (mismo ítem, distintas olas)
perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1     ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1     ~~ prefcontact2

# Regresión de factores sobre cohorte (control)
percmerit1  ~ cohortdummy
percmerit2  ~ cohortdummy
percnmerit1 ~ cohortdummy
percnmerit2 ~ cohortdummy
prefmerit1  ~ cohortdummy
prefmerit2  ~ cohortdummy
prefnmerit1 ~ cohortdummy
prefnmerit2 ~ cohortdummy
')

# Estimación del modelo
fit_configural_cohort <- sem(model_configural_cohort, data = db_invariance,
                         ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                     "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                     "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                     "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                         parameterization = "theta",
                         estimator = "WLSMV")

```

```{r}
#| label: weak-cohort
#| tbl-cap: "Weak Conditional Invariance"
#| results: asis
#| echo: false
#| warning: false

loadinginv_model_cohort <- ('

# Igualación de cargas (invarianza débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Umbrales (uno igualado por ítem)

# perceffort1 | pe1t1*t1 + pe1t2*t2
# perceffort2 | pe2t1*t1 + pe2t2*t2
# perctalent1 | pt1t1*t1 + pt1t2*t2
# perctalent2 | pt2t1*t1 + pt2t2*t2
# percrichparents1 | prp1t1*t1 + prp1t2*t2
# percrichparents2 | prp2t1*t1 + prp2t2*t2
# perccontact1 | pc1t1*t1 + pc1t2*t2
# perccontact2 | pc2t1*t1 + pc2t2*t2
# prefeffort1 | pre1t1*t1 + pre1t2*t2
# prefeffort2 | pre2t1*t1 + pre2t2*t2
# preftalent1 | prt1t1*t1 + prt1t2*t2
# preftalent2 | prt2t1*t1 + prt2t2*t2
# prefrichparents1 | pfrp1t1*t1 + pfrp1t2*t2
# prefrichparents2 | pfrp2t1*t1 + pfrp2t2*t2
# prefcontact1 | pfc1t1*t1 + pfc1t2*t2
# prefcontact2 | pfc2t1*t1 + pfc2t2*t2
 

# Covarianzas entre errores

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2

# Regresión de factores sobre cohorte (control)
percmerit1  ~ cohortdummy
percmerit2  ~ cohortdummy
percnmerit1 ~ cohortdummy
percnmerit2 ~ cohortdummy
prefmerit1  ~ cohortdummy
prefmerit2  ~ cohortdummy
prefnmerit1 ~ cohortdummy
prefnmerit2 ~ cohortdummy
')


fit_loadinginv_cohort <- sem(loadinginv_model_cohort, data = db_invariance,
                      ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                  "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                  "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                  "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                      parameterization = "theta",
                      estimator = "WLSMV")
```

```{r}
#| label: strong-cohort
#| tbl-cap: "Strong Conditional Invariance"
#| results: asis
#| echo: false
#| warning: false

thresholdinv_model_cohort <- ('

# Igualación de cargas (como en el modelo débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Thresholds iguales entre olas (invarianza fuerte)

perceffort1     | pe_t1*t1 + pe_t2*t2
perceffort2     | pe_t1*t1 + pe_t2*t2
perctalent1     | pt_t1*t1 + pt_t2*t2
perctalent2     | pt_t1*t1 + pt_t2*t2
percrichparents1| prp_t1*t1 + prp_t2*t2
percrichparents2| prp_t1*t1 + prp_t2*t2
perccontact1    | pc_t1*t1 + pc_t2*t2
perccontact2    | pc_t1*t1 + pc_t2*t2
prefeffort1     | pre_t1*t1 + pre_t2*t2
prefeffort2     | pre_t1*t1 + pre_t2*t2
preftalent1     | prt_t1*t1 + prt_t2*t2
preftalent2     | prt_t1*t1 + prt_t2*t2
prefrichparents1| pfrp_t1*t1 + pfrp_t2*t2
prefrichparents2| pfrp_t1*t1 + pfrp_t2*t2
prefcontact1    | pfc_t1*t1 + pfc_t2*t2
prefcontact2    | pfc_t1*t1 + pfc_t2*t2


# Interceptos fijos

perceffort1 + perctalent1 ~ 0*1
perceffort2 + perctalent2 ~ 0*1
percrichparents1 + perccontact1 ~ 0*1
percrichparents2 + perccontact2 ~ 0*1
prefeffort1 + preftalent1 ~ 0*1
prefeffort2 + preftalent2 ~ 0*1
prefrichparents1 + prefcontact1 ~ 0*1
prefrichparents2 + prefcontact2 ~ 0*1


# Varianzas únicas

perceffort1 ~~ 1*perceffort1
perctalent1 ~~ 1*perctalent1
percrichparents1 ~~ 1*percrichparents1
perccontact1 ~~ 1*perccontact1
prefeffort1 ~~ 1*prefeffort1
preftalent1 ~~ 1*preftalent1
prefrichparents1 ~~ 1*prefrichparents1
prefcontact1 ~~ 1*prefcontact1

perceffort2 ~~ NA*perceffort2
perctalent2 ~~ NA*perctalent2
percrichparents2 ~~ NA*percrichparents2
perccontact2 ~~ NA*perccontact2
prefeffort2 ~~ NA*prefeffort2
preftalent2 ~~ NA*preftalent2
prefrichparents2 ~~ NA*prefrichparents2
prefcontact2 ~~ NA*prefcontact2


# Covarianzas entre errores longitudinales

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2

# Regresión de factores sobre cohorte (control)
percmerit1  ~ cohortdummy
percmerit2  ~ cohortdummy
percnmerit1 ~ cohortdummy
percnmerit2 ~ cohortdummy
prefmerit1  ~ cohortdummy
prefmerit2  ~ cohortdummy
prefnmerit1 ~ cohortdummy
prefnmerit2 ~ cohortdummy
')

fit_thresholdinv_cohort <- sem(thresholdinv_model_cohort, data = db_invariance,
                        ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                    "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                    "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                    "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                        parameterization = "theta",
                        estimator = "WLSMV")
```

```{r}
#| label: strict-cohort
#| tbl-cap: "Strict Conditional Invariance"
#| results: asis
#| echo: false
#| warning: false

uniquenessinv_model_cohort <- ('

# Cargas factoriales (invarianza débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas de factores latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Medias latentes

percmerit1  ~ 0*1
percmerit2  ~ 1
percnmerit1 ~ 0*1
percnmerit2 ~ 1
prefmerit1  ~ 0*1
prefmerit2  ~ 1
prefnmerit1 ~ 0*1
prefnmerit2 ~ 1


# Umbrales (invarianza fuerte)

perceffort1     | pe_t1*t1 + pe_t2*t2
perceffort2     | pe_t1*t1 + pe_t2*t2
perctalent1     | pt_t1*t1 + pt_t2*t2
perctalent2     | pt_t1*t1 + pt_t2*t2
percrichparents1| prp_t1*t1 + prp_t2*t2
percrichparents2| prp_t1*t1 + prp_t2*t2
perccontact1    | pc_t1*t1 + pc_t2*t2
perccontact2    | pc_t1*t1 + pc_t2*t2
prefeffort1     | pre_t1*t1 + pre_t2*t2
prefeffort2     | pre_t1*t1 + pre_t2*t2
preftalent1     | prt_t1*t1 + prt_t2*t2
preftalent2     | prt_t1*t1 + prt_t2*t2
prefrichparents1| pfrp_t1*t1 + pfrp_t2*t2
prefrichparents2| pfrp_t1*t1 + pfrp_t2*t2
prefcontact1    | pfc_t1*t1 + pfc_t2*t2
prefcontact2    | pfc_t1*t1 + pfc_t2*t2


# Interceptos fijos

perceffort1 + perctalent1 ~ 0*1
perceffort2 + perctalent2 ~ 0*1
percrichparents1 + perccontact1 ~ 0*1
percrichparents2 + perccontact2 ~ 0*1
prefeffort1 + preftalent1 ~ 0*1
prefeffort2 + preftalent2 ~ 0*1
prefrichparents1 + prefcontact1 ~ 0*1
prefrichparents2 + prefcontact2 ~ 0*1


# Varianzas únicas (invarianza estricta)
# Fijadas a 1 en todas las olas

perceffort1 ~~ 1*perceffort1
perceffort2 ~~ 1*perceffort2
perctalent1 ~~ 1*perctalent1
perctalent2 ~~ 1*perctalent2

percrichparents1 ~~ 1*percrichparents1
percrichparents2 ~~ 1*percrichparents2
perccontact1 ~~ 1*perccontact1
perccontact2 ~~ 1*perccontact2

prefeffort1 ~~ 1*prefeffort1
prefeffort2 ~~ 1*prefeffort2
preftalent1 ~~ 1*preftalent1
preftalent2 ~~ 1*preftalent2

prefrichparents1 ~~ 1*prefrichparents1
prefrichparents2 ~~ 1*prefrichparents2
prefcontact1 ~~ 1*prefcontact1
prefcontact2 ~~ 1*prefcontact2


# Covarianzas entre errores (mismo ítem, diferente ola)

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2

# Regresión de factores sobre cohorte (control)
percmerit1  ~ cohortdummy
percmerit2  ~ cohortdummy
percnmerit1 ~ cohortdummy
percnmerit2 ~ cohortdummy
prefmerit1  ~ cohortdummy
prefmerit2  ~ cohortdummy
prefnmerit1 ~ cohortdummy
prefnmerit2 ~ cohortdummy
')

fit_uniquenessinv_cohort <- sem(uniquenessinv_model_cohort, data = db_invariance,
                         ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                     "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                     "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                     "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                         parameterization = "theta",
                         estimator = "WLSMV")
```




Despite the absence of cohort measurement invariance, we examined whether plausible cohort-related heterogeneity could compromise longitudinal invariance by re-estimating the longitudinal invariance sequence while controlling for cohort (dummy-coded) as a covariate predicting each latent factor. Model fit remained good across all steps—from the configural baseline to the strict model—and consistently met conventional standards; for instance, the strict invariance model with cohort control showed $\chi^2$(92) = 131.64, CFI = .991, and RMSEA = .027 [0.016–0.037]. Importantly, including cohort as a predictor did not materially alter model fit or the invariance conclusions, suggesting that the equality constraints over time are tenable even after accounting for cohort differences in average factor levels.



```{r}
#| label: tbl-conditional
#| tbl-cap: "Conditional longitudinal invariance by cohort level"
#| tbl-cap-location: top
#| echo: false
#| warning: false

# Compare fit

an1 <- anova(fit_configural_cohort, fit_loadinginv_cohort)
an2 <- anova(fit_loadinginv_cohort, fit_thresholdinv_cohort)
an3 <- anova(fit_thresholdinv_cohort, fit_uniquenessinv_cohort)

tab01 <- bind_rows(
  as_tibble(an1)[2,],
  as_tibble(an2)[2,],
  as_tibble(an3)[2,]
) %>%
  select("Chisq", "Df", chisq_diff = `Chisq diff`, df_diff = `Df diff`, pvalue = `Pr(>Chisq)`) %>%
  mutate(
    stars = stars.pval(pvalue),
    chisqt = paste0(round(Chisq, 2), " (", Df, ")"),
    decision = ifelse(pvalue > 0.05, "Accept", "Reject"),
    model = c("Weak", "Strong", "Strict")
  ) %>%
  bind_rows(
    tibble(Chisq = an1$Chisq[1], Df = an1$Df[1], chisq_diff = NA, df_diff = NA,
           pvalue = NA, stars = "", chisqt = paste0(round(an1$Chisq[1], 2), " (", an1$Df[1], ")"),
           decision = "Reference", model = "Configural")
  ) %>%
  select(model, chisqt, chisq_diff, df_diff, pvalue, stars, decision) %>%
  mutate(model = factor(model, levels = c("Configural", "Weak", "Strong", "Strict"))) %>%
  arrange(model)


fit.meas <- dplyr::bind_rows(lavaan::fitmeasures(fit_configural_cohort, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_loadinginv_cohort,  output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_thresholdinv_cohort, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_uniquenessinv_cohort, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),])

fit.meas <- fit.meas %>%
  dplyr::mutate(diff.chi2 = chisq    - lag(chisq,default = dplyr::first(chisq)),
                diff.df   = df       - lag(df,   default = dplyr::first(df)),
                diff.cfi  = cfi      - lag(cfi,  default = dplyr::first(cfi)),
                diff.rmsea   = rmsea - lag(rmsea,default = dplyr::first(rmsea))) %>%
  round(3) %>%
  dplyr::mutate(rmsea.ci=paste0(rmsea," \n ", "(",rmsea.ci.lower,"-",rmsea.ci.upper,")"))

tab.inv <- dplyr::bind_cols(tab01,fit.meas) %>%
  dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.df,diff.cfi,diff.rmsea,stars,decision) %>%
  dplyr::mutate(diff.chi2=paste0(diff.chi2," (",diff.df,") ",stars)) %>%
  dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.cfi,diff.rmsea,decision)


col.nam <- c("Model","&chi;^2 (df)","CFI","RMSEA (90 CI)",
             "&Delta; &chi;^2 (&Delta; df)","&Delta; CFI","&Delta; RMSEA","Decision")

tab.inv %>% 
  kableExtra::kable(format = "html",
                    align = "c",
                    booktabs = T,
                    escape = F,
                    caption = NULL,
                    col.names = col.nam) %>%
  kableExtra::kable_styling(full_width = T,
                            latex_options = "hold_position",
                            bootstrap_options=c("striped", "bordered", "condensed"),
                            font_size = 23) %>%
  kableExtra::column_spec(c(1,8), width = "3.5cm") %>% 
  kableExtra::column_spec(2:7, width = "4cm") %>% 
  kableExtra::column_spec(4, width = "5cm")
```

This result has two main implications. First, it strengthens the claim that the measurement properties of the scale are temporally stable within individuals: observed over-time comparisons are not driven by shifts in how primary versus secondary students use the response categories, but reflect stability (or change) in the underlying latent constructs. Second, it clarifies the scope of the cohort non-invariance finding. Non-invariance across cohorts appears to be primarily a cross-sectional comparability problem—limiting direct comparisons of latent means or observed scores between educational levels at a given wave—rather than a threat to longitudinal analyses pooling both cohorts. Therefore, analyses of within-person change and over-time associations can be interpreted with greater confidence, while cohort contrasts should be treated cautiously (or handled via partial invariance, alignment, or cohort-specific models).


