---
author: "Equipo EDUMER"
bibliography: "../input/bib/merit-factorial.bib"
csl: "../input/bib/apa6.csl"
---

# Results

```{r}
#| label: set
#| echo: false
#| message: false
#| warning: false

library(knitr)

knitr::opts_chunk$set(echo = F,
                      warning = F,
                      error = F, 
                      message = F) 

table_format <- if (is_html_output()) {
  "html"
} else if (is_latex_output()) {
  "latex"
}
table_format2 <- if (is_html_output()) {
  T
} else if (is_latex_output()) {
  F
}

options(kableExtra.html.bsTable = T)
options(knitr.kable.NA = "")
```

```{r}
#| label: packages
#| include: false
#| echo: false

if (!require("pacman")) install.packages("pacman")

pacman::p_load(
  tidyverse,
  sjmisc,
  sjPlot,
  here,
  lavaan,
  psych,
  corrplot,
  ggdist,
  patchwork,
  semTools,
  gtools,
  kableExtra
)

options(scipen = 999)
rm(list = ls())
```

```{r}
#| label: longitudinal data 
#| echo: false
#| output: false

load(file = here("output", "data", "db_long_proc.RData"))

names(db_long)
glimpse(db_long)
dim(db_long)
```

```{r}
#| label: cohort data
#| echo: false

db1 <- db_long %>%
filter(ola == 1) %>%
select(-c(ola, curse_level, p20, p21_ano, age)) %>%
na.omit()

```

## Cohort Invariance Test

```{r}
#| label: Measurement model
#| include: false 

model_cfa <- '
perc_merit = ~ perc_effort + perc_talent
perc_nmerit = ~ perc_rich_parents + perc_contact
pref_merit = ~ pref_effort + pref_talent
pref_nmerit = ~ pref_rich_parents + pref_contact
perc_effort ~~ pref_talent
'

model_restricted <- '
perc_merit = ~ perc_effort + perc_talent
perc_nmerit = ~ a*perc_rich_parents + a*perc_contact
pref_merit = ~ pref_effort + pref_talent
pref_nmerit = ~ pref_rich_parents + pref_contact
perc_effort ~~ pref_talent
'
```

```{r}
#| label: Models by cohort
#| output: false

mgeneral_cfa <- cfa(model = model_restricted, 
                   data = db1, 
                   estimator = "WLSMV",
                   ordered = T,
                   std.lv = F)

mbasica_cfa <- cfa(model = model_restricted, 
                   data = subset(db1, cohort_level == "Primary"), 
                   estimator = "WLSMV",
                   ordered = T,
                   std.lv = F)

mmedia_cfa <- cfa(model = model_restricted, 
                  data = subset(db1, cohort_level == "Secondary"), 
                  estimator = "WLSMV",
                  ordered = T,
                  std.lv = F)
```

```{r}
#| include: false 

summary(mmedia_cfa, standardized = TRUE, fit.measures = TRUE)
summary(mbasica_cfa, standardized = TRUE, fit.measures = TRUE)
```

```{r}
#| label: tbl-factorload
#| include: false
#| message: false

cnames <- c("Factor","Indicator","Loadings Básica","Loadings Media")
kable(left_join(x = standardizedsolution(mbasica_cfa) %>%
                  filter(op=="=~") %>%
                  select(lhs,rhs,est.std),y = standardizedsolution(mmedia_cfa) %>%
                  filter(op=="=~") %>%
                  select(lhs,rhs,est.std),c("lhs","rhs")),
      format = "markdown",digits = 2,col.names = cnames, caption = "Factor loadings")

```

![](imagenes/esquema-basica.jpg)

The diagram shows the standardized factor loadings estimated with WLSMV for the primary and secondary education models. One of the first findings is that within each cohort, the loadings vary depending on the factor. In the case of the primary education model, the loadings of both meritocratic perception indicators are quite similar, with perception of effort at .60 and perception of talent at .71. In contrast, in the non-meritocratic preferences factor, the loadings vary greatly, with preference for effort being .46 and preference for talent being .86. This suggests that the factor explains the second factor more than the first. Finally, the indicators of the non-meritocratic preferences factor vary, but not as strongly.

![](imagenes/esquema-media.jpg)

In the secondary education model, some similarities can be seen in comparison to the primary model. The indicators of the meritocratic perception factor have slightly higher loadings than in the previous model, but they do not differ as much from each other. The difference in the indicators of meritocratic preference is reversed, with preference for effort becoming the highest (.76) and preference for talent the lowest (0.41). With regard to non-meritocratic preferences, the indicators have much more similar factor loadings than in the primary school model.

```{r}
#| label: tbl-fitcohort
#| tbl-cap: Summary fit indices of three models
#| echo: false

fit_measures <- rbind(
  "General" = fitMeasures(mgeneral_cfa,
                           c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr")),
  "Primary" = fitMeasures(mbasica_cfa,
                         c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr")),
  "Secondary" = fitMeasures(mmedia_cfa,
                        c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr"))
)

knitr::kable(fit_measures, digits = 3, caption = "Fit indexes by model")

```

@tbl-fitcohort shows the fit indices for each of the three models. All models achieved a non-significant chi-square, which could be expected given their sensitivity to large samples, such as those used in this study.

The first model is the general model, i.e., the one that includes primary and secondary school students. It can be seen that it has good fit indices (CFI=0.989, RMSEA=0.048, $\chi^2$(df=14)=41.026), so we can conclude that the four latent factor scale works well for students.

The second model contains data from primary students. In this case, the fit indices work acceptable (CFI=0.975, RMSEA=0.063, $\chi^2$(df=14)=36. 295). In this case, the scale has less validation than for the previous model.

It is noteworthy that, for the secondary education model, most indicators have values that are close to perfect (CFI=1, RMSEA=0, $\chi^2$(df=14)=11.779). However, the results of this model could be overfitting, so they should be interpreted with caution.

```{r}
#| label: configural model
#| include: false 

baseline <- measEq.syntax(
  configural.model = model_restricted,
  data = db1,
  ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact", 
              "pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"),
  parameterization = "delta",
  ID.fac = "std.lv",
  ID.cat = "Wu.Estabrook.2016",
  group = "cohort_level",
  group.equal = "configural"
)

model.baseline <- as.character(baseline)

fit.baseline <- cfa(model.baseline, data = db1, group = "cohort_level",
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact", 
              "pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"))

summary(fit.baseline)
```

```{r}
#| label: weak model
#| include: false

thresholds <- measEq.syntax(
configural.model = model_restricted,
data = db1,
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact",
"pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"),
parameterization = "delta",
ID.fac = "std.lv",
ID.cat = "Wu.Estabrook.2016",
group = "cohort_level",
group.equal = c("thresholds")
)

model.thres <- as.character(thresholds)

fit.thres <- cfa(model.thres, data = db1, group = "cohort_level",
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact",
"pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"))

summary(fit.thres, fit.measures = TRUE)
```

```{r}
#| label: loading-threshold model
#| include: false

strong <- measEq.syntax(
configural.model = model_restricted,
data = db1,
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact",
"pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"),
parameterization = "delta",
ID.fac = "std.lv",
ID.cat = "Wu.Estabrook.2016",
group = "cohort_level",
group.equal = c("thresholds", "loadings")
)

model.strong <- as.character(strong)

fit.strong <- cfa(model.strong, data = db1, group = "cohort_level",
ordered = c("perc_effort", "perc_talent", "perc_rich_parents", "perc_contact",
"pref_effort", "pref_talent", "pref_rich_parents", "pref_contact"))

summary(fit.strong, fit.measures = TRUE)

```

```{r}
#| label: cohort-table
#| echo: false

# Comparaciones de Chi²
an1 <- anova(fit.baseline, fit.thres)
an2 <- anova(fit.thres, fit.strong)

tab01 <- bind_rows(
  as_tibble(an1)[2,],
  as_tibble(an2)[2,]
) %>%
  select("Chisq", "Df", chisq.diff = `Chisq diff`, df.diff = `Df diff`, pvalue = `Pr(>Chisq)`) %>%
  mutate(
    stars = stars.pval(pvalue),
    chisqt = paste0(round(Chisq, 2), " (", Df, ")"),
    decision = ifelse(pvalue > 0.05, "Accept", "Reject"),
    model = c("Weak", "Strong")
  ) %>%
  bind_rows(
    tibble(
      Chisq = an1$Chisq[1],
      Df = an1$Df[1],
      chisq.diff = NA,
      df.diff = NA,
      pvalue = NA,
      stars = "",
      chisqt = paste0(round(an1$Chisq[1], 2), " (", an1$Df[1], ")"),
      decision = "Reference",
      model = "Configural"
    )
  ) %>%
  select(model, chisqt, chisq.diff, df.diff, pvalue, stars, decision) %>%
  mutate(model = factor(model, levels = c("Configural", "Weak", "Strong"))) %>%
  arrange(model)

# Medidas de ajuste
fit.meas <- bind_rows(
  fitMeasures(fit.baseline, output = "matrix")[c("chisq", "df", "cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"),],
  fitMeasures(fit.thres, output = "matrix")[c("chisq", "df", "cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"),],
  fitMeasures(fit.strong, output = "matrix")[c("chisq", "df", "cfi", "rmsea", "rmsea.ci.lower", "rmsea.ci.upper"),]
)

fit.meas <- fit.meas %>%
  mutate(
    diff.chi2 = chisq - lag(chisq, default = first(chisq)),
    diff.df = df - lag(df, default = first(df)),
    diff.cfi = cfi - lag(cfi, default = first(cfi)),
    diff.rmsea = rmsea - lag(rmsea, default = first(rmsea))
  ) %>%
  round(3) %>%
  mutate(rmsea.ci = paste0(rmsea, " \n(", rmsea.ci.lower, "-", rmsea.ci.upper, ")"))

# Tabla final (mantener diff.df hasta formatear)
tab.inv <- bind_cols(tab01, fit.meas) %>%
  select(model, chisqt, cfi, rmsea.ci, diff.chi2, diff.df, diff.cfi, diff.rmsea, stars, decision) %>%
  mutate(diff.chi2 = paste0(diff.chi2, " (", diff.df, ") ", stars)) %>%
  select(model, chisqt, cfi, rmsea.ci, diff.chi2, diff.cfi, diff.rmsea, decision)

# Encabezados de columna
col.nam <- c(
  "Model", "&chi;^2 (df)", "CFI", "RMSEA (90 CI)",
  "&Delta; &chi;^2 (&Delta; df)", "&Delta; CFI", "&Delta; RMSEA", "Decision"
)

# Salida en kable
tab.inv %>%
  kableExtra::kable(
    format = "html",
    align = "c",
    booktabs = TRUE,
    escape = FALSE,
    col.names = col.nam
  ) %>%
  kableExtra::kable_styling(
    full_width = TRUE,
    latex_options = "hold_position",
    bootstrap_options = c("striped", "bordered", "condensed"),
    font_size = 23
  ) %>%
  kableExtra::column_spec(c(1, 8), width = "3.5cm") %>%
  kableExtra::column_spec(2:7, width = "4cm") %>%
  kableExtra::column_spec(4, width = "5cm")



```

The results of the different invariance models are displayed at the previous table. To examine invariance across cohorts the same steps in Dubravka et al. (2019) were followed, who propose the estimation of three models: the configural model, another restricting the thresholds, and finally restricting the thresholds and factor loadings.

The configural model was first estimated, which maintains the same factor structure for both baseline and midline. The configural model has good fit indices (CFI = 0.992, RMSEA = 0.037), so there is empirical evidence that the factor structure behaves stably in both groups.

Looking at the thresholds restricted model, it appears that when thresholds are restricted to equality, the four-factor latent model is not equivalent across the different cohorts in the study in accordance with @chen_sensitivity_2007 ($\Delta$CFI -.014 \< -. 01); $\Delta$RMSEA .019 \> .015). This result implies that by restricting thresholds, the meritocracy scale varies between primary and secondary education. In this case, invariance is not satisfied.

The level represented as strong restricts both thresholds and factor loadings. When compared with the previous level of invariance, it can be seen that the criteria for assuming that the meritocracy scale remains stable across cohorts are not met either. ($\Delta$CFI -.005 \< -. 01); $\Delta$RMSEA .003 \< .015), so invariance is rejected.

It is pertinent to ask to what extent these results are due to the instability of the secondary education model. An attempt was made to resolve its overfitting, but this was not possible, which may have had direct implications for this part of the analysis.

## Longitudinal Invariance

```{r}
#| label: data 2
#| results: asis
#| echo: false
#| warning: false
#| output: false

# Crear base en formato wide con dummy de cohorte (0 = primaria, 1 = secundaria)
db_invariance <- db_long %>%
  group_by(id_estudiante) %>%
  mutate(
    cohort_level = first(cohort_level),
    cohort_dummy = case_when(
      cohort_level == "Primary" ~ 0,
      cohort_level == "Secondary" ~ 1,
      TRUE ~ NA_real_
    )
  ) %>%
  ungroup() %>%
  select(id_estudiante, cohort_dummy, ola, starts_with(c("perc", "pref"))) %>%
  pivot_wider(
    id_cols = c(id_estudiante, cohort_dummy),
    names_from = ola,
    names_glue = "{.value}{ola}",
    values_from = c(
      perc_effort, perc_talent,
      perc_rich_parents, perc_contact,
      pref_effort, pref_talent,
      pref_rich_parents, pref_contact
    )
  ) %>%
  na.omit() %>%
  rename_with(~ str_replace_all(., "_", ""))

# Reescalar variables y convertir a ordinales
db_invariance <- db_invariance %>% 
  mutate(
    across(
      .cols = -c(idestudiante, cohortdummy),
      .fns = ~ case_when(. == 1 ~ 0,
                         . == 2 ~ 1,
                         . == 3 ~ 2,
                         . == 4 ~ 3)
    )
  ) %>%
  mutate(
    across(
      .cols = -c(idestudiante),
      .fns = ~ ordered(.)
    )
  )
```

```{r}
#| label: conf-model
#| tbl-cap: "Longitudinal Invariance Test"
#| results: asis
#| echo: false
#| warning: false

# First, define the configural model, using the repeated measures factors and
# indicators
baseline_model_smt <- ('

###########################################
# Definición de factores (1 marcador por factor)
###########################################

percmerit1  =~ 1*perceffort1     + perctalent1
percmerit2  =~ 1*perceffort2     + perctalent2

percnmerit1 =~ 1*percrichparents1 + perccontact1
percnmerit2 =~ 1*percrichparents2 + perccontact2

prefmerit1  =~ 1*prefeffort1     + preftalent1
prefmerit2  =~ 1*prefeffort2     + preftalent2

prefnmerit1 =~ 1*prefrichparents1 + prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + prefcontact2


###########################################
# Covarianzas entre errores (mismo ítem, distintas olas)
###########################################

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2

percrichparents1 ~~ percrichparents2
perccontact1     ~~ perccontact2

prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2

prefrichparents1 ~~ prefrichparents2
prefcontact1     ~~ prefcontact2
')



# Model Estimation
fit_baseline <- cfa(baseline_model_smt, data = db_invariance,
                    ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                    parameterization = "theta",
                    estimator = "WLSMV")
```

```{r}
#| label: Weak-Model
#| tbl-cap: "Longitudinal Invariance Weak Model"
#| results: asis
#| echo: false
#| warning: false

loadinginv_model_smt <- ('

# Igualación de cargas (invarianza débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Umbrales (uno igualado por ítem)

# perceffort1 | pe1t1*t1 + pe1t2*t2
# perceffort2 | pe2t1*t1 + pe2t2*t2
# perctalent1 | pt1t1*t1 + pt1t2*t2
# perctalent2 | pt2t1*t1 + pt2t2*t2
# percrichparents1 | prp1t1*t1 + prp1t2*t2
# percrichparents2 | prp2t1*t1 + prp2t2*t2
# perccontact1 | pc1t1*t1 + pc1t2*t2
# perccontact2 | pc2t1*t1 + pc2t2*t2
# prefeffort1 | pre1t1*t1 + pre1t2*t2
# prefeffort2 | pre2t1*t1 + pre2t2*t2
# preftalent1 | prt1t1*t1 + prt1t2*t2
# preftalent2 | prt2t1*t1 + prt2t2*t2
# prefrichparents1 | pfrp1t1*t1 + pfrp1t2*t2
# prefrichparents2 | pfrp2t1*t1 + pfrp2t2*t2
# prefcontact1 | pfc1t1*t1 + pfc1t2*t2
# prefcontact2 | pfc2t1*t1 + pfc2t2*t2
 

# Covarianzas entre errores

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2
')


fit_loadinginv <- cfa(loadinginv_model_smt, data = db_invariance,
                      ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                  "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                  "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                  "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                      parameterization = "theta",
                      estimator = "WLSMV")
```

```{r}
#| label: strong-model
#| tbl-cap: "Longitudinal Invariance Strong Model"
#| results: asis
#| echo: false
#| warning: false

thresholdinv_model_smt <- ('

# Igualación de cargas (como en el modelo débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Thresholds iguales entre olas (invarianza fuerte)

perceffort1     | pe_t1*t1 + pe_t2*t2
perceffort2     | pe_t1*t1 + pe_t2*t2
perctalent1     | pt_t1*t1 + pt_t2*t2
perctalent2     | pt_t1*t1 + pt_t2*t2
percrichparents1| prp_t1*t1 + prp_t2*t2
percrichparents2| prp_t1*t1 + prp_t2*t2
perccontact1    | pc_t1*t1 + pc_t2*t2
perccontact2    | pc_t1*t1 + pc_t2*t2
prefeffort1     | pre_t1*t1 + pre_t2*t2
prefeffort2     | pre_t1*t1 + pre_t2*t2
preftalent1     | prt_t1*t1 + prt_t2*t2
preftalent2     | prt_t1*t1 + prt_t2*t2
prefrichparents1| pfrp_t1*t1 + pfrp_t2*t2
prefrichparents2| pfrp_t1*t1 + pfrp_t2*t2
prefcontact1    | pfc_t1*t1 + pfc_t2*t2
prefcontact2    | pfc_t1*t1 + pfc_t2*t2


# Interceptos fijos

perceffort1 + perctalent1 ~ 0*1
perceffort2 + perctalent2 ~ 0*1
percrichparents1 + perccontact1 ~ 0*1
percrichparents2 + perccontact2 ~ 0*1
prefeffort1 + preftalent1 ~ 0*1
prefeffort2 + preftalent2 ~ 0*1
prefrichparents1 + prefcontact1 ~ 0*1
prefrichparents2 + prefcontact2 ~ 0*1


# Varianzas únicas

perceffort1 ~~ 1*perceffort1
perctalent1 ~~ 1*perctalent1
percrichparents1 ~~ 1*percrichparents1
perccontact1 ~~ 1*perccontact1
prefeffort1 ~~ 1*prefeffort1
preftalent1 ~~ 1*preftalent1
prefrichparents1 ~~ 1*prefrichparents1
prefcontact1 ~~ 1*prefcontact1

perceffort2 ~~ NA*perceffort2
perctalent2 ~~ NA*perctalent2
percrichparents2 ~~ NA*percrichparents2
perccontact2 ~~ NA*perccontact2
prefeffort2 ~~ NA*prefeffort2
preftalent2 ~~ NA*preftalent2
prefrichparents2 ~~ NA*prefrichparents2
prefcontact2 ~~ NA*prefcontact2


# Covarianzas entre errores longitudinales

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2
')

fit_thresholdinv <- cfa(thresholdinv_model_smt, data = db_invariance,
                        ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                    "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                    "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                    "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                        parameterization = "theta",
                        estimator = "WLSMV")
```

```{r}
#| label: strict-model
#| tbl-cap: "Longitudinal Invariance Strict Model"
#| results: asis
#| echo: false
#| warning: false

uniquenessinv_model_smt <- ('

# Cargas factoriales (invarianza débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas de factores latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Medias latentes

percmerit1  ~ 0*1
percmerit2  ~ 1
percnmerit1 ~ 0*1
percnmerit2 ~ 1
prefmerit1  ~ 0*1
prefmerit2  ~ 1
prefnmerit1 ~ 0*1
prefnmerit2 ~ 1


# Umbrales (invarianza fuerte)

perceffort1     | pe_t1*t1 + pe_t2*t2
perceffort2     | pe_t1*t1 + pe_t2*t2
perctalent1     | pt_t1*t1 + pt_t2*t2
perctalent2     | pt_t1*t1 + pt_t2*t2
percrichparents1| prp_t1*t1 + prp_t2*t2
percrichparents2| prp_t1*t1 + prp_t2*t2
perccontact1    | pc_t1*t1 + pc_t2*t2
perccontact2    | pc_t1*t1 + pc_t2*t2
prefeffort1     | pre_t1*t1 + pre_t2*t2
prefeffort2     | pre_t1*t1 + pre_t2*t2
preftalent1     | prt_t1*t1 + prt_t2*t2
preftalent2     | prt_t1*t1 + prt_t2*t2
prefrichparents1| pfrp_t1*t1 + pfrp_t2*t2
prefrichparents2| pfrp_t1*t1 + pfrp_t2*t2
prefcontact1    | pfc_t1*t1 + pfc_t2*t2
prefcontact2    | pfc_t1*t1 + pfc_t2*t2


# Interceptos fijos

perceffort1 + perctalent1 ~ 0*1
perceffort2 + perctalent2 ~ 0*1
percrichparents1 + perccontact1 ~ 0*1
percrichparents2 + perccontact2 ~ 0*1
prefeffort1 + preftalent1 ~ 0*1
prefeffort2 + preftalent2 ~ 0*1
prefrichparents1 + prefcontact1 ~ 0*1
prefrichparents2 + prefcontact2 ~ 0*1


# Varianzas únicas (invarianza estricta)
# Fijadas a 1 en todas las olas

perceffort1 ~~ 1*perceffort1
perceffort2 ~~ 1*perceffort2
perctalent1 ~~ 1*perctalent1
perctalent2 ~~ 1*perctalent2

percrichparents1 ~~ 1*percrichparents1
percrichparents2 ~~ 1*percrichparents2
perccontact1 ~~ 1*perccontact1
perccontact2 ~~ 1*perccontact2

prefeffort1 ~~ 1*prefeffort1
prefeffort2 ~~ 1*prefeffort2
preftalent1 ~~ 1*preftalent1
preftalent2 ~~ 1*preftalent2

prefrichparents1 ~~ 1*prefrichparents1
prefrichparents2 ~~ 1*prefrichparents2
prefcontact1 ~~ 1*prefcontact1
prefcontact2 ~~ 1*prefcontact2


# Covarianzas entre errores (mismo ítem, diferente ola)

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2
')

fit_uniquenessinv <- cfa(uniquenessinv_model_smt, data = db_invariance,
                         ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                     "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                     "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                     "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                         parameterization = "theta",
                         estimator = "WLSMV")
```

A series of nested confirmatory factor analysis (CFA) models were estimated to assess the longitudinal measurement invariance of the constructs across the two waves of the study. The evaluation began with the configural model, which allows all parameters (loadings, intercepts, and residuals) to vary freely and just compare the same factor structure within individuals in time. This model served as the baseline for subsequent comparisons and demonstrated good fit to the data, with $\chi^2$(68) = 117.7, a Comparative Fit Index (CFI) of 0.991, and a Root Mean Square Error of Approximation (RMSEA) of 0.035, with a 90% confidence interval ranging from 0.024 to 0.046. These indices suggest that the same factorial structure is replicated across time points, meaning that the general configuration of items and latent variables remains stable.

```{r}
#| tbl-cap: "Longitudinal invariance results"
#| tbl-cap-location: top
#| echo: false
#| warning: false
#| label: tbl-longinv

# Compare fit

an1 <- anova(fit_baseline, fit_loadinginv)
an2 <- anova(fit_loadinginv, fit_thresholdinv)
an3 <- anova(fit_thresholdinv, fit_uniquenessinv)

tab01 <- bind_rows(
  as_tibble(an1)[2,],
  as_tibble(an2)[2,],
  as_tibble(an3)[2,]
) %>%
  select("Chisq", "Df", chisq_diff = `Chisq diff`, df_diff = `Df diff`, pvalue = `Pr(>Chisq)`) %>%
  mutate(
    stars = stars.pval(pvalue),
    chisqt = paste0(round(Chisq, 2), " (", Df, ")"),
    decision = ifelse(pvalue > 0.05, "Accept", "Reject"),
    model = c("Weak", "Strong", "Strict")
  ) %>%
  bind_rows(
    tibble(Chisq = an1$Chisq[1], Df = an1$Df[1], chisq_diff = NA, df_diff = NA,
           pvalue = NA, stars = "", chisqt = paste0(round(an1$Chisq[1], 2), " (", an1$Df[1], ")"),
           decision = "Reference", model = "Configural")
  ) %>%
  select(model, chisqt, chisq_diff, df_diff, pvalue, stars, decision) %>%
  mutate(model = factor(model, levels = c("Configural", "Weak", "Strong", "Strict"))) %>%
  arrange(model)


fit.meas <- dplyr::bind_rows(lavaan::fitmeasures(fit_baseline, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_loadinginv,  output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_thresholdinv, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_uniquenessinv, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),])

fit.meas <- fit.meas %>%
  dplyr::mutate(diff.chi2 = chisq    - lag(chisq,default = dplyr::first(chisq)),
                diff.df   = df       - lag(df,   default = dplyr::first(df)),
                diff.cfi  = cfi      - lag(cfi,  default = dplyr::first(cfi)),
                diff.rmsea   = rmsea - lag(rmsea,default = dplyr::first(rmsea))) %>%
  round(3) %>%
  dplyr::mutate(rmsea.ci=paste0(rmsea," \n ", "(",rmsea.ci.lower,"-",rmsea.ci.upper,")"))

tab.inv <- dplyr::bind_cols(tab01,fit.meas) %>%
  dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.df,diff.cfi,diff.rmsea,stars,decision) %>%
  dplyr::mutate(diff.chi2=paste0(diff.chi2," (",diff.df,") ",stars)) %>%
  dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.cfi,diff.rmsea,decision)


col.nam <- c("Model","&chi;^2 (df)","CFI","RMSEA (90 CI)",
             "&Delta; &chi;^2 (&Delta; df)","&Delta; CFI","&Delta; RMSEA","Decision")

tab.inv %>% 
  kableExtra::kable(format = "html",
                    align = "c",
                    booktabs = T,
                    escape = F,
                    caption = NULL,
                    col.names = col.nam) %>%
  kableExtra::kable_styling(full_width = T,
                            latex_options = "hold_position",
                            bootstrap_options=c("striped", "bordered", "condensed"),
                            font_size = 23) %>%
  kableExtra::column_spec(c(1,8), width = "3.5cm") %>% 
  kableExtra::column_spec(2:7, width = "4cm") %>% 
  kableExtra::column_spec(4, width = "5cm")
```

Subsequently, the weak invariance model was tested by constraining the factor loadings to be equal across waves. This model also showed a fit that passes the acceptable standards indicated by the literature: $\chi^2$(72) = 122.51, CFI = 0.990, RMSEA = 0.034 (90% CI: 0.024–0.045). The comparison with the configural model revealed a negligible and non-significant change in model fit, with $\Delta \chi^2$(4) = 4.809, $\Delta$CFI = 0.000, and $\Delta$RMSEA = -0.001. These results support the assumption of weak invariance, indicating that the strength of the relationship between items and latent constructs is consistent over time, i.e., within students.

The strong invariance model introduced additional constraints by setting item intercepts and loadings equal across time points, in addition to the equality of thresholds. Fixing thresholds is relevant to ensure that response categories represent equivalent levels of the latent construct across group or time. Whitout threshold invariance, comparisons of latent means may be biased due to differences in how caregories are interpreted rather than true differences in the construct [@liu_testing_2017]. This model yielded a $\chi^2$(80) = 128.53, CFI = 0.991, and RMSEA = 0.032 (90% CI: 0.021–0.042). The changes in fit statistics relative to the weak model were $\Delta \chi^2$(8) = 6.02, $\Delta$CFI = 0.000, and $\Delta$RMSEA = -0.002. These minimal differences suggest that the additional constraints did not significantly impair the model’s fit. Therefore, strong invariance is supported, meaning that individuals with the same latent trait level are expected to have the same observed item scores across waves.

Finally, the strict invariance model imposed equality constraints on residual variances in addition to the loadings and intercepts. This model also showed good fit: $\chi^2$(84) = 130.17, CFI = 0.991, RMSEA = 0.031 (90% CI: 0.020–0.040). The comparison with the strong model revealed a $\Delta \chi^2$(4) = 1.635, $\Delta$CFI = 0.000, and $\Delta$RMSEA = -0.002. These changes are minimal and fall well within recommended thresholds for model comparison, indicating that strict invariance is also supported.

In summary, the results support full longitudinal measurement invariance—configural, weak, strong, and strict—suggesting that the constructs are measured equivalently across time. This justifies meaningful comparisons of latent means, variances, and covariances over time, and provides strong evidence of the temporal stability and psychometric robustness of the measurement model. However, it remains important to explore possible sources of misfit or localized non-invariance that could inform refinements to further improve the model.

In parallel, to detect potential sources of local misfit and evaluate the robustness of longitudinal measurement invariance, an univariate score tests was estimated at each level of the invariance hierarchy: configural, metric (weak), scalar (strong), and strict. Using the `lavTestScore()` function in *lavaan*, we tested whether specific equality constraints—such as equal loadings, thresholds, or residual variances across time—introduced statistically significant misfit. This method enables the identification of individual parameters that may violate invariance assumptions, even when global model fit remains acceptable.

Across all three constrained models (metric, scalar, and strict), the score tests revealed no significant violations. At the metric level, all loading constraints were supported. In the scalar model, both loadings and thresholds showed stability over time, with no indication of misfit. Finally, under strict invariance, residual variances and thresholds were also found to be invariant across waves. The largest test statistic ($\chi^2$ = 3.829, p = .050) was observed for a threshold in *preference for talent indicator*, yet this did not reach significance.

These results provide strong evidence that full longitudinal measurement invariance holds in the data. The measurement model is stable over time in terms, supporting meaningful comparison of latent variable means, variances, and structural relations across time. Full results of the score tests, including all tested constraints and their associated statistics, are presented in the supplementary materials.

## Conditional Longitudinal Invariance

```{r}
#| echo: false
#| warning: false

# Modelo CFA configural con cohorte como covariable (control)
model_configural_cohort <- ('
percmerit1  =~ 1*perceffort1     + perctalent1
percmerit2  =~ 1*perceffort2     + perctalent2
percnmerit1 =~ 1*percrichparents1 + perccontact1
percnmerit2 =~ 1*percrichparents2 + perccontact2
prefmerit1  =~ 1*prefeffort1     + preftalent1
prefmerit2  =~ 1*prefeffort2     + preftalent2
prefnmerit1 =~ 1*prefrichparents1 + prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + prefcontact2

# Covarianzas entre errores (mismo ítem, distintas olas)
perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1     ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1     ~~ prefcontact2

# Regresión de factores sobre cohorte (control)
percmerit1  ~ cohortdummy
percmerit2  ~ cohortdummy
percnmerit1 ~ cohortdummy
percnmerit2 ~ cohortdummy
prefmerit1  ~ cohortdummy
prefmerit2  ~ cohortdummy
prefnmerit1 ~ cohortdummy
prefnmerit2 ~ cohortdummy
')

# Estimación del modelo
fit_configural_cohort <- sem(model_configural_cohort, data = db_invariance,
                         ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                     "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                     "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                     "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                         parameterization = "theta",
                         estimator = "WLSMV")

```

```{r}
#| label: weak-cohort
#| tbl-cap: "Weak Conditional Invariance"
#| results: asis
#| echo: false
#| warning: false

loadinginv_model_cohort <- ('

# Igualación de cargas (invarianza débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Umbrales (uno igualado por ítem)

# perceffort1 | pe1t1*t1 + pe1t2*t2
# perceffort2 | pe2t1*t1 + pe2t2*t2
# perctalent1 | pt1t1*t1 + pt1t2*t2
# perctalent2 | pt2t1*t1 + pt2t2*t2
# percrichparents1 | prp1t1*t1 + prp1t2*t2
# percrichparents2 | prp2t1*t1 + prp2t2*t2
# perccontact1 | pc1t1*t1 + pc1t2*t2
# perccontact2 | pc2t1*t1 + pc2t2*t2
# prefeffort1 | pre1t1*t1 + pre1t2*t2
# prefeffort2 | pre2t1*t1 + pre2t2*t2
# preftalent1 | prt1t1*t1 + prt1t2*t2
# preftalent2 | prt2t1*t1 + prt2t2*t2
# prefrichparents1 | pfrp1t1*t1 + pfrp1t2*t2
# prefrichparents2 | pfrp2t1*t1 + pfrp2t2*t2
# prefcontact1 | pfc1t1*t1 + pfc1t2*t2
# prefcontact2 | pfc2t1*t1 + pfc2t2*t2
 

# Covarianzas entre errores

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2

# Regresión de factores sobre cohorte (control)
percmerit1  ~ cohortdummy
percmerit2  ~ cohortdummy
percnmerit1 ~ cohortdummy
percnmerit2 ~ cohortdummy
prefmerit1  ~ cohortdummy
prefmerit2  ~ cohortdummy
prefnmerit1 ~ cohortdummy
prefnmerit2 ~ cohortdummy
')


fit_loadinginv_cohort <- sem(loadinginv_model_cohort, data = db_invariance,
                      ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                  "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                  "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                  "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                      parameterization = "theta",
                      estimator = "WLSMV")
```

```{r}
#| label: strong-cohort
#| tbl-cap: "Strong Conditional Invariance"
#| results: asis
#| echo: false
#| warning: false

thresholdinv_model_cohort <- ('

# Igualación de cargas (como en el modelo débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Thresholds iguales entre olas (invarianza fuerte)

perceffort1     | pe_t1*t1 + pe_t2*t2
perceffort2     | pe_t1*t1 + pe_t2*t2
perctalent1     | pt_t1*t1 + pt_t2*t2
perctalent2     | pt_t1*t1 + pt_t2*t2
percrichparents1| prp_t1*t1 + prp_t2*t2
percrichparents2| prp_t1*t1 + prp_t2*t2
perccontact1    | pc_t1*t1 + pc_t2*t2
perccontact2    | pc_t1*t1 + pc_t2*t2
prefeffort1     | pre_t1*t1 + pre_t2*t2
prefeffort2     | pre_t1*t1 + pre_t2*t2
preftalent1     | prt_t1*t1 + prt_t2*t2
preftalent2     | prt_t1*t1 + prt_t2*t2
prefrichparents1| pfrp_t1*t1 + pfrp_t2*t2
prefrichparents2| pfrp_t1*t1 + pfrp_t2*t2
prefcontact1    | pfc_t1*t1 + pfc_t2*t2
prefcontact2    | pfc_t1*t1 + pfc_t2*t2


# Interceptos fijos

perceffort1 + perctalent1 ~ 0*1
perceffort2 + perctalent2 ~ 0*1
percrichparents1 + perccontact1 ~ 0*1
percrichparents2 + perccontact2 ~ 0*1
prefeffort1 + preftalent1 ~ 0*1
prefeffort2 + preftalent2 ~ 0*1
prefrichparents1 + prefcontact1 ~ 0*1
prefrichparents2 + prefcontact2 ~ 0*1


# Varianzas únicas

perceffort1 ~~ 1*perceffort1
perctalent1 ~~ 1*perctalent1
percrichparents1 ~~ 1*percrichparents1
perccontact1 ~~ 1*perccontact1
prefeffort1 ~~ 1*prefeffort1
preftalent1 ~~ 1*preftalent1
prefrichparents1 ~~ 1*prefrichparents1
prefcontact1 ~~ 1*prefcontact1

perceffort2 ~~ NA*perceffort2
perctalent2 ~~ NA*perctalent2
percrichparents2 ~~ NA*percrichparents2
perccontact2 ~~ NA*perccontact2
prefeffort2 ~~ NA*prefeffort2
preftalent2 ~~ NA*preftalent2
prefrichparents2 ~~ NA*prefrichparents2
prefcontact2 ~~ NA*prefcontact2


# Covarianzas entre errores longitudinales

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2

# Regresión de factores sobre cohorte (control)
percmerit1  ~ cohortdummy
percmerit2  ~ cohortdummy
percnmerit1 ~ cohortdummy
percnmerit2 ~ cohortdummy
prefmerit1  ~ cohortdummy
prefmerit2  ~ cohortdummy
prefnmerit1 ~ cohortdummy
prefnmerit2 ~ cohortdummy
')

fit_thresholdinv_cohort <- sem(thresholdinv_model_cohort, data = db_invariance,
                        ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                    "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                    "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                    "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                        parameterization = "theta",
                        estimator = "WLSMV")
```

```{r}
#| label: strict-cohort
#| tbl-cap: "Strict Conditional Invariance"
#| results: asis
#| echo: false
#| warning: false

uniquenessinv_model_cohort <- ('

# Cargas factoriales (invarianza débil)

percmerit1  =~ 1*perceffort1 + pe_loading*perctalent1
percmerit2  =~ 1*perceffort2 + pe_loading*perctalent2

percnmerit1 =~ 1*percrichparents1 + prc_loading*perccontact1
percnmerit2 =~ 1*percrichparents2 + prc_loading*perccontact2

prefmerit1  =~ 1*prefeffort1 + pfe_loading*preftalent1
prefmerit2  =~ 1*prefeffort2 + pfe_loading*preftalent2

prefnmerit1 =~ 1*prefrichparents1 + pfrc_loading*prefcontact1
prefnmerit2 =~ 1*prefrichparents2 + pfrc_loading*prefcontact2


# Varianzas y covarianzas de factores latentes

percmerit1  ~~ percmerit1 + percmerit2
percmerit2  ~~ percmerit2
percnmerit1 ~~ percnmerit1 + percnmerit2
percnmerit2 ~~ percnmerit2
prefmerit1  ~~ prefmerit1 + prefmerit2
prefmerit2  ~~ prefmerit2
prefnmerit1 ~~ prefnmerit1 + prefnmerit2
prefnmerit2 ~~ prefnmerit2


# Medias latentes

percmerit1  ~ 0*1
percmerit2  ~ 1
percnmerit1 ~ 0*1
percnmerit2 ~ 1
prefmerit1  ~ 0*1
prefmerit2  ~ 1
prefnmerit1 ~ 0*1
prefnmerit2 ~ 1


# Umbrales (invarianza fuerte)

perceffort1     | pe_t1*t1 + pe_t2*t2
perceffort2     | pe_t1*t1 + pe_t2*t2
perctalent1     | pt_t1*t1 + pt_t2*t2
perctalent2     | pt_t1*t1 + pt_t2*t2
percrichparents1| prp_t1*t1 + prp_t2*t2
percrichparents2| prp_t1*t1 + prp_t2*t2
perccontact1    | pc_t1*t1 + pc_t2*t2
perccontact2    | pc_t1*t1 + pc_t2*t2
prefeffort1     | pre_t1*t1 + pre_t2*t2
prefeffort2     | pre_t1*t1 + pre_t2*t2
preftalent1     | prt_t1*t1 + prt_t2*t2
preftalent2     | prt_t1*t1 + prt_t2*t2
prefrichparents1| pfrp_t1*t1 + pfrp_t2*t2
prefrichparents2| pfrp_t1*t1 + pfrp_t2*t2
prefcontact1    | pfc_t1*t1 + pfc_t2*t2
prefcontact2    | pfc_t1*t1 + pfc_t2*t2


# Interceptos fijos

perceffort1 + perctalent1 ~ 0*1
perceffort2 + perctalent2 ~ 0*1
percrichparents1 + perccontact1 ~ 0*1
percrichparents2 + perccontact2 ~ 0*1
prefeffort1 + preftalent1 ~ 0*1
prefeffort2 + preftalent2 ~ 0*1
prefrichparents1 + prefcontact1 ~ 0*1
prefrichparents2 + prefcontact2 ~ 0*1


# Varianzas únicas (invarianza estricta)
# Fijadas a 1 en todas las olas

perceffort1 ~~ 1*perceffort1
perceffort2 ~~ 1*perceffort2
perctalent1 ~~ 1*perctalent1
perctalent2 ~~ 1*perctalent2

percrichparents1 ~~ 1*percrichparents1
percrichparents2 ~~ 1*percrichparents2
perccontact1 ~~ 1*perccontact1
perccontact2 ~~ 1*perccontact2

prefeffort1 ~~ 1*prefeffort1
prefeffort2 ~~ 1*prefeffort2
preftalent1 ~~ 1*preftalent1
preftalent2 ~~ 1*preftalent2

prefrichparents1 ~~ 1*prefrichparents1
prefrichparents2 ~~ 1*prefrichparents2
prefcontact1 ~~ 1*prefcontact1
prefcontact2 ~~ 1*prefcontact2


# Covarianzas entre errores (mismo ítem, diferente ola)

perceffort1 ~~ perceffort2
perctalent1 ~~ perctalent2
percrichparents1 ~~ percrichparents2
perccontact1 ~~ perccontact2
prefeffort1 ~~ prefeffort2
preftalent1 ~~ preftalent2
prefrichparents1 ~~ prefrichparents2
prefcontact1 ~~ prefcontact2

# Regresión de factores sobre cohorte (control)
percmerit1  ~ cohortdummy
percmerit2  ~ cohortdummy
percnmerit1 ~ cohortdummy
percnmerit2 ~ cohortdummy
prefmerit1  ~ cohortdummy
prefmerit2  ~ cohortdummy
prefnmerit1 ~ cohortdummy
prefnmerit2 ~ cohortdummy
')

fit_uniquenessinv_cohort <- sem(uniquenessinv_model_cohort, data = db_invariance,
                         ordered = c("perceffort1", "perctalent1", "perceffort2", "perctalent2",
                                     "percrichparents1", "perccontact1", "percrichparents2", "perccontact2",
                                     "prefeffort1", "preftalent1", "prefeffort2", "preftalent2",
                                     "prefrichparents1", "prefcontact1", "prefrichparents2", "prefcontact2"),
                         parameterization = "theta",
                         estimator = "WLSMV")
```

Although no evidence was found in favor of measurement invariance between cohorts, the analysis nevertheless explored the potential heterogeneity associated with cohort differences, given the plausible expectation of their impact on socialization processes. To evaluate the robustness of longitudinal measurement invariance over time while accounting for these effects, a series of nested models were estimated, both with and without controlling for cohort through a dummy variable predicting each latent factor.

All models presented fit indices that exceed commonly accepted standards in the literature, with CFI values above .990 and RMSEA values below .035. The configural model ($\chi^2$ = 117.70, df = 68, CFI = .991, RMSEA = .035 \[.024–.046\]) served as the baseline, and subsequent models imposing equality constraints on factor loadings (weak invariance), intercepts (strong invariance), and residual variances (strict invariance) showed negligible changes in fit indices (e.g., $\Delta$CFI ≤ .001 across all steps). This pattern held even after including cohort as a covariate: for instance, the strict invariance model with cohort control yielded $\chi^2$ = 134.21 (df = 92), CFI = .991, and RMSEA = .028 \[.017–.038\], closely resembling the model without cohort control ($\chi^2$ = 130.17, df = 84, CFI = .991, RMSEA = .031 \[.020–.040\]). These results support the conclusion that full longitudinal measurement invariance is maintained, regardless of cohort-related heterogeneity.

```{r}
#| label: tbl-conditional
#| tbl-cap: "Conditional longitudinal invariance by cohort level"
#| tbl-cap-location: top
#| echo: false
#| warning: false

# Compare fit

an1 <- anova(fit_configural_cohort, fit_loadinginv_cohort)
an2 <- anova(fit_loadinginv_cohort, fit_thresholdinv_cohort)
an3 <- anova(fit_thresholdinv_cohort, fit_uniquenessinv_cohort)

tab01 <- bind_rows(
  as_tibble(an1)[2,],
  as_tibble(an2)[2,],
  as_tibble(an3)[2,]
) %>%
  select("Chisq", "Df", chisq_diff = `Chisq diff`, df_diff = `Df diff`, pvalue = `Pr(>Chisq)`) %>%
  mutate(
    stars = stars.pval(pvalue),
    chisqt = paste0(round(Chisq, 2), " (", Df, ")"),
    decision = ifelse(pvalue > 0.05, "Accept", "Reject"),
    model = c("Weak", "Strong", "Strict")
  ) %>%
  bind_rows(
    tibble(Chisq = an1$Chisq[1], Df = an1$Df[1], chisq_diff = NA, df_diff = NA,
           pvalue = NA, stars = "", chisqt = paste0(round(an1$Chisq[1], 2), " (", an1$Df[1], ")"),
           decision = "Reference", model = "Configural")
  ) %>%
  select(model, chisqt, chisq_diff, df_diff, pvalue, stars, decision) %>%
  mutate(model = factor(model, levels = c("Configural", "Weak", "Strong", "Strict"))) %>%
  arrange(model)


fit.meas <- dplyr::bind_rows(lavaan::fitmeasures(fit_configural_cohort, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_loadinginv_cohort,  output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_thresholdinv_cohort, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                             lavaan::fitmeasures(fit_uniquenessinv_cohort, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),])

fit.meas <- fit.meas %>%
  dplyr::mutate(diff.chi2 = chisq    - lag(chisq,default = dplyr::first(chisq)),
                diff.df   = df       - lag(df,   default = dplyr::first(df)),
                diff.cfi  = cfi      - lag(cfi,  default = dplyr::first(cfi)),
                diff.rmsea   = rmsea - lag(rmsea,default = dplyr::first(rmsea))) %>%
  round(3) %>%
  dplyr::mutate(rmsea.ci=paste0(rmsea," \n ", "(",rmsea.ci.lower,"-",rmsea.ci.upper,")"))

tab.inv <- dplyr::bind_cols(tab01,fit.meas) %>%
  dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.df,diff.cfi,diff.rmsea,stars,decision) %>%
  dplyr::mutate(diff.chi2=paste0(diff.chi2," (",diff.df,") ",stars)) %>%
  dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.cfi,diff.rmsea,decision)


col.nam <- c("Model","&chi;^2 (df)","CFI","RMSEA (90 CI)",
             "&Delta; &chi;^2 (&Delta; df)","&Delta; CFI","&Delta; RMSEA","Decision")

tab.inv %>% 
  kableExtra::kable(format = "html",
                    align = "c",
                    booktabs = T,
                    escape = F,
                    caption = NULL,
                    col.names = col.nam) %>%
  kableExtra::kable_styling(full_width = T,
                            latex_options = "hold_position",
                            bootstrap_options=c("striped", "bordered", "condensed"),
                            font_size = 23) %>%
  kableExtra::column_spec(c(1,8), width = "3.5cm") %>% 
  kableExtra::column_spec(2:7, width = "4cm") %>% 
  kableExtra::column_spec(4, width = "5cm")
```

Substantively, these results suggest that the factor structure and measurement properties of the constructs are stable over time and are not significantly influenced by cohort membership. The consistency of the fit indices before and after controlling for cohort indicates that observed longitudinal invariance is not an artifact of generational differences. This strengthens the validity of our interpretations regarding temporal stability and change in the latent constructs under study.
